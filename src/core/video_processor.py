# /top_eye/src/core/video_processor_advanced.py
import cv2
import torch
import numpy as np
from threading import Thread, Lock
from queue import Queue
from datetime import datetime, timedelta
import time
import os
import pickle
import hashlib
from collections import deque
import json


class VideoProcessor:
    def __init__(self, config):
        self.config = config
        print(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–ª—è –∫–∞–º–µ—Ä—ã: {config.CAMERA_ID}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã
        self.cap = None
        self.last_reconnect = time.time()
        self.reconnect_interval = 5

        # –û—á–µ—Ä–µ–¥–∏
        self.frame_queue = Queue(maxsize=10)
        self.processed_queue = Queue(maxsize=10)
        self.lock = Lock()
        self.running = False

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.current_count = 0
        self.today_unique = set()
        self.session_unique = set()
        self.visitor_history = {}  # –ò—Å—Ç–æ—Ä–∏—è –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self.total_visitors = 0

        # –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–∞—è –ø–∞–º—è—Ç—å
        self.active_tracks = {}  # –ê–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏ {track_id: data}
        self.inactive_tracks = {}  # –ù–µ–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏ (–µ—â–µ –≤ –ø–∞–º—è—Ç–∏)
        self.known_visitors = {}  # –ò–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–∏ (–¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–∞—è –ø–∞–º—è—Ç—å)
        self.next_track_id = 1000  # –ù–∞—á–∏–Ω–∞–µ–º —Å –±–æ–ª—å—à–æ–≥–æ —á–∏—Å–ª–∞

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç—Ä–µ–∫–∏–Ω–≥–∞
        self.max_disappeared = 60  # –∫–∞–¥—Ä–æ–≤ –¥–æ –ø–µ—Ä–µ—Ö–æ–¥–∞ –≤ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ
        self.max_forget = 300  # –∫–∞–¥—Ä–æ–≤ –¥–æ –ø–æ–ª–Ω–æ–≥–æ –∑–∞–±—ã–≤–∞–Ω–∏—è
        self.reid_threshold = 0.6  # –ø–æ—Ä–æ–≥ –¥–ª—è re-identification

        # YOLO –º–æ–¥–µ–ª—å
        self.model = None

        # ReID –º–æ–¥–µ–ª—å (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
        self.reid_model = None

        # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
        self.visitors_db_path = "data/visitors.db"
        self._load_visitors_db()

        print("‚úì –í–∏–¥–µ–æ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç—å—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")

    def _load_visitors_db(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            if os.path.exists(self.visitors_db_path):
                with open(self.visitors_db_path, 'rb') as f:
                    data = pickle.load(f)
                    self.known_visitors = data.get('known_visitors', {})
                    self.next_track_id = data.get('next_track_id', 1000)
                print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.known_visitors)} –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π")
        except:
            print("‚ö† –ù–æ–≤–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π")
            self.known_visitors = {}

    def _save_visitors_db(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        try:
            os.makedirs(os.path.dirname(self.visitors_db_path), exist_ok=True)
            data = {
                'known_visitors': self.known_visitors,
                'next_track_id': self.next_track_id,
                'saved_at': datetime.now().isoformat()
            }
            with open(self.visitors_db_path, 'wb') as f:
                pickle.dump(data, f)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö: {e}")

    def init_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"""
        try:
            print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")

            # YOLOv8
            from ultralytics import YOLO
            model_path = self.config.YOLO_MODEL_PATH

            if not os.path.exists(model_path):
                print("–°–∫–∞—á–∏–≤–∞–µ–º YOLOv8n...")
                model_path = 'yolov8n.pt'

            self.model = YOLO(model_path)
            self.model.to('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"‚úì YOLO –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {'CUDA' if torch.cuda.is_available() else 'CPU'}")

            # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π ReID (—Ü–≤–µ—Ç–æ–≤—ã–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã + CNN —Ñ–∏—á–∏)
            self._init_reid_model()

        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")

    def _init_reid_model(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π ReID –º–æ–¥–µ–ª–∏"""
        print("‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π ReID –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ü–≤–µ—Ç–æ–≤—ã—Ö –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º")

    def _extract_reid_features(self, image):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è ReID"""
        if image is None or image.size == 0:
            return None

        try:
            features = {}

            # 1. –¶–≤–µ—Ç–æ–≤—ã–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã (HSV)
            hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
            h_hist = cv2.calcHist([hsv], [0], None, [16], [0, 180])
            s_hist = cv2.calcHist([hsv], [1], None, [8], [0, 256])
            v_hist = cv2.calcHist([hsv], [2], None, [8], [0, 256])

            features['color_hist'] = np.concatenate([
                h_hist.flatten() / np.sum(h_hist),
                s_hist.flatten() / np.sum(s_hist),
                v_hist.flatten() / np.sum(v_hist)
            ])

            # 2. –¢–µ–∫—Å—Ç—É—Ä–∞ (LBP —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π)
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            lbp_features = self._simplified_lbp(gray)
            features['texture'] = lbp_features

            # 3. –†–∞–∑–º–µ—Ä –∏ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
            h, w = image.shape[:2]
            features['aspect_ratio'] = w / h if h > 0 else 1
            features['area'] = w * h

            # 4. –î–æ–º–∏–Ω–∏—Ä—É—é—â–∏–µ —Ü–≤–µ—Ç–∞
            pixels = image.reshape(-1, 3)
            colors, counts = np.unique(pixels, axis=0, return_counts=True)
            top_colors = colors[np.argsort(-counts)[:3]]
            features['dominant_colors'] = top_colors.flatten()

            return features

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return None

    def _simplified_lbp(self, gray):
        """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π LBP –¥–ª—è —Ç–µ–∫—Å—Ç—É—Ä—ã"""
        try:
            # –†–µ—Å–∞–π–∑ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            small = cv2.resize(gray, (32, 64))

            # –ü—Ä–æ—Å—Ç–æ–π –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫
            sobelx = cv2.Sobel(small, cv2.CV_64F, 1, 0, ksize=3)
            sobely = cv2.Sobel(small, cv2.CV_64F, 0, 1, ksize=3)

            magnitude = np.sqrt(sobelx ** 2 + sobely ** 2)
            orientation = np.arctan2(sobely, sobelx)

            # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –∏ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
            mag_mean = np.mean(magnitude)
            mag_binary = (magnitude > mag_mean).flatten()
            ori_mean = np.mean(orientation)
            ori_binary = (orientation > ori_mean).flatten()

            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ö–µ—à
            combined = np.concatenate([mag_binary, ori_binary])
            return combined.astype(np.float32)

        except:
            return np.zeros(32 * 64 * 2, dtype=np.float32)

    def _compare_features(self, features1, features2):
        """–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –Ω–∞–±–æ—Ä–æ–≤ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤"""
        if features1 is None or features2 is None:
            return 0

        similarity = 0
        weights = {'color': 0.4, 'texture': 0.3, 'appearance': 0.3}

        try:
            # 1. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ü–≤–µ—Ç–æ–≤—ã—Ö –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º (–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—è)
            if 'color_hist' in features1 and 'color_hist' in features2:
                color_sim = np.corrcoef(features1['color_hist'], features2['color_hist'])[0, 1]
                similarity += weights['color'] * max(0, color_sim)

            # 2. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç—É—Ä—ã (cosine similarity)
            if 'texture' in features1 and 'texture' in features2:
                vec1 = features1['texture'].flatten()
                vec2 = features2['texture'].flatten()
                if len(vec1) > 0 and len(vec2) > 0:
                    cos_sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2) + 1e-10)
                    similarity += weights['texture'] * max(0, cos_sim)

            # 3. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–π
            if 'aspect_ratio' in features1 and 'aspect_ratio' in features2:
                ar_diff = abs(features1['aspect_ratio'] - features2['aspect_ratio'])
                ar_sim = max(0, 1 - ar_diff)
                similarity += 0.1 * ar_sim

            # 4. –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö —Ü–≤–µ—Ç–æ–≤
            if 'dominant_colors' in features1 and 'dominant_colors' in features2:
                colors1 = features1['dominant_colors'].reshape(-1, 3)
                colors2 = features2['dominant_colors'].reshape(-1, 3)
                color_dists = []
                for c1 in colors1:
                    for c2 in colors2:
                        dist = np.linalg.norm(c1 - c2)
                        color_dists.append(dist)
                if color_dists:
                    color_sim = max(0, 1 - min(color_dists) / 100)
                    similarity += 0.2 * color_sim

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")

        return min(1.0, similarity)

    def start(self):
        """–ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        self.running = True
        self.init_models()
        Thread(target=self._capture_frames, daemon=True).start()
        Thread(target=self._process_frames, daemon=True).start()
        Thread(target=self._manage_memory, daemon=True).start()  # –ü–æ—Ç–æ–∫ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é
        print("‚úì –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ –∑–∞–ø—É—â–µ–Ω–∞")

    def _capture_frames(self):
        """–ó–∞—Ö–≤–∞—Ç –∫–∞–¥—Ä–æ–≤"""
        frame_count = 0

        while self.running:
            try:
                if self.cap is None or not self.cap.isOpened():
                    if time.time() - self.last_reconnect > self.reconnect_interval:
                        print("–ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ...")
                        self._reconnect_camera()
                        time.sleep(1)
                        continue
                    else:
                        time.sleep(0.1)
                        continue

                success, frame = self.cap.read()

                if not success:
                    print("‚úó –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
                    self.cap.release()
                    self.cap = None
                    continue

                if frame_count % self.config.PROCESS_EVERY_N_FRAMES == 0:
                    if not self.frame_queue.full():
                        self.frame_queue.put(frame.copy())

                frame_count += 1
                time.sleep(0.01)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞: {e}")
                if self.cap:
                    self.cap.release()
                    self.cap = None
                time.sleep(1)

    def _reconnect_camera(self):
        """–ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ"""
        try:
            if self.cap:
                self.cap.release()

            print(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫: {self.config.RTSP_URL}")
            self.cap = cv2.VideoCapture(self.config.RTSP_URL)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)
            self.cap.set(cv2.CAP_PROP_FPS, self.config.FPS)

            time.sleep(0.5)

            if self.cap.isOpened():
                print("‚úì –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
                self.last_reconnect = time.time()
                return True
            else:
                print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –∫–∞–º–µ—Ä–µ")
                return False

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            return False

    def _process_frames(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤"""
        while self.running:
            try:
                if not self.frame_queue.empty():
                    frame = self.frame_queue.get()
                    processed_data = self._process_single_frame(frame)

                    if not self.processed_queue.full():
                        self.processed_queue.put(processed_data)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

    def _manage_memory(self):
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç—å—é"""
        while self.running:
            try:
                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—á–µ—Ç—á–∏–∫–∏ –Ω–µ–∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                current_time = time.time()

                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏ –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–∏
                tracks_to_remove = []
                for track_id, track_data in list(self.active_tracks.items()):
                    if current_time - track_data['last_seen'] > self.max_disappeared / 30:
                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –≤ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ
                        self.inactive_tracks[track_id] = track_data
                        tracks_to_remove.append(track_id)

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–∏ –µ—Å–ª–∏ —Ç—Ä–µ–∫ –±—ã–ª –¥–æ–ª–≥–∏–º
                        if track_data['age'] > 30:
                            visitor_id = f"visitor_{track_id}"
                            self.known_visitors[visitor_id] = {
                                'features': track_data['features'],
                                'last_seen': current_time,
                                'first_seen': track_data['first_seen'],
                                'visit_count': track_data.get('visit_count', 0) + 1
                            }

                for track_id in tracks_to_remove:
                    del self.active_tracks[track_id]

                # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏
                inactive_to_remove = []
                for track_id, track_data in list(self.inactive_tracks.items()):
                    if current_time - track_data['last_seen'] > self.max_forget / 30:
                        inactive_to_remove.append(track_id)

                for track_id in inactive_to_remove:
                    del self.inactive_tracks[track_id]

                # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
                if int(time.time()) % 60 == 0:  # –ö–∞–∂–¥—É—é –º–∏–Ω—É—Ç—É
                    self._save_visitors_db()

                time.sleep(1)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é —Å–µ–∫—É–Ω–¥—É

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –ø–∞–º—è—Ç—å—é: {e}")
                time.sleep(5)

    def _process_single_frame(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∫–∞–¥—Ä–∞"""
        result = {
            'frame': frame.copy(),
            'detections': [],
            'timestamp': datetime.now(),
            'people_count': 0,
            'fps': 0,
            'known_visitors': 0
        }

        try:
            if self.model is not None:
                start_time = time.time()

                # YOLO –¥–µ—Ç–µ–∫—Ü–∏—è
                with torch.no_grad():
                    yolo_results = self.model(
                        frame,
                        conf=self.config.CONFIDENCE_THRESHOLD,
                        device='cuda' if torch.cuda.is_available() else 'cpu',
                        verbose=False,
                        classes=[0]
                    )

                # –¢–µ–∫—É—â–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
                current_detections = []
                if yolo_results and len(yolo_results) > 0:
                    yolo_result = yolo_results[0]

                    if yolo_result.boxes is not None and len(yolo_result.boxes) > 0:
                        boxes = yolo_result.boxes.xyxy.cpu().numpy()
                        confidences = yolo_result.boxes.conf.cpu().numpy()

                        for i in range(len(boxes)):
                            x1, y1, x2, y2 = boxes[i].astype(int)
                            conf = float(confidences[i])

                            width = x2 - x1
                            height = y2 - y1

                            if width > 30 and height > 60:
                                # –í—ã—Ä–µ–∑–∞–µ–º —Ä–µ–≥–∏–æ–Ω —á–µ–ª–æ–≤–µ–∫–∞
                                person_roi = frame[y1:y2, x1:x2]

                                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è ReID
                                features = self._extract_reid_features(person_roi)

                                current_detections.append({
                                    'bbox': [float(x1), float(y1), float(x2), float(y2)],
                                    'center': [(x1 + x2) / 2, (y1 + y2) / 2],
                                    'confidence': conf,
                                    'width': width,
                                    'height': height,
                                    'roi': person_roi,
                                    'features': features,
                                    'area': width * height
                                })

                # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —Å –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç—å—é
                tracked_detections = self._advanced_tracking(current_detections)

                # –û–±–Ω–æ–≤–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏
                current_time = time.time()
                known_count = 0

                for det in tracked_detections:
                    track_id = det['track_id']

                    if track_id not in self.active_tracks:
                        # –ù–æ–≤—ã–π —Ç—Ä–µ–∫ - –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ª–∏ —ç—Ç–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å
                        matched_visitor = self._find_matching_visitor(det['features'])
                        if matched_visitor:
                            # –ù–∞—à–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è!
                            track_id = matched_visitor['id']
                            known_count += 1
                            print(f"‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω –∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å ID: {track_id}")

                        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ç—Ä–µ–∫
                        self.active_tracks[track_id] = {
                            'bbox': det['bbox'],
                            'last_seen': current_time,
                            'first_seen': current_time,
                            'features': det['features'],
                            'age': 1,
                            'visit_count': 1,
                            'is_known': matched_visitor is not None
                        }
                    else:
                        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π —Ç—Ä–µ–∫
                        self.active_tracks[track_id].update({
                            'bbox': det['bbox'],
                            'last_seen': current_time,
                            'features': det['features'],
                            'age': self.active_tracks[track_id]['age'] + 1
                        })
                        if self.active_tracks[track_id].get('is_known'):
                            known_count += 1

                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    result['detections'].append({
                        'track_id': track_id,
                        'bbox': det['bbox'],
                        'confidence': det['confidence'],
                        'age': self.active_tracks[track_id]['age'],
                        'is_known': self.active_tracks[track_id].get('is_known', False)
                    })

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                result['people_count'] = len(result['detections'])
                result['known_visitors'] = known_count
                self.current_count = result['people_count']

                # –û–±–Ω–æ–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π
                for det in result['detections']:
                    track_id = det['track_id']
                    if self.active_tracks[track_id]['age'] > 15:  # –£—Å—Ç–æ–π—á–∏–≤—ã–π —Ç—Ä–µ–∫
                        self.session_unique.add(track_id)
                        today = datetime.now().date().isoformat()
                        self.today_unique.add(f"{today}_{track_id}")

                        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                        if track_id not in self.visitor_history:
                            self.visitor_history[track_id] = {
                                'first_seen': current_time,
                                'last_seen': current_time,
                                'visit_count': 1,
                                'total_time': 0
                            }
                        else:
                            self.visitor_history[track_id]['last_seen'] = current_time
                            self.visitor_history[track_id]['visit_count'] += 1

                # FPS
                end_time = time.time()
                result['fps'] = 1.0 / (end_time - start_time) if (end_time - start_time) > 0 else 0

                # –†–∏—Å—É–µ–º –Ω–∞ –∫–∞–¥—Ä–µ
                self._draw_detections(frame, result['detections'])

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–∞–¥—Ä–∞: {e}")

        return result

    def _find_matching_visitor(self, features):
        """–ü–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è–º–∏"""
        if features is None or not self.known_visitors:
            return None

        best_match = None
        best_score = 0

        for visitor_id, visitor_data in self.known_visitors.items():
            if 'features' in visitor_data:
                score = self._compare_features(features, visitor_data['features'])
                if score > self.reid_threshold and score > best_score:
                    best_score = score
                    best_match = {
                        'id': int(visitor_id.split('_')[1]) if '_' in visitor_id else visitor_id,
                        'score': score,
                        'data': visitor_data
                    }

        return best_match

    def _advanced_tracking(self, current_detections):
        """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —Å —É—á–µ—Ç–æ–º –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏"""
        if not current_detections:
            return []

        result = []

        # 1. –°–Ω–∞—á–∞–ª–∞ –ø—ã—Ç–∞–µ–º—Å—è —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —Å –∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Ç—Ä–µ–∫–∞–º–∏
        matched_detections = set()
        matched_tracks = set()

        if self.active_tracks:
            # –ú–∞—Ç—Ä–∏—Ü–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏
            similarity_matrix = []

            for i, det in enumerate(current_detections):
                for track_id, track_data in self.active_tracks.items():
                    # –í—ã—á–∏—Å–ª—è–µ–º IoU
                    iou = self._compute_iou(det['bbox'], track_data['bbox'])

                    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ü–µ–Ω—Ç—Ä–∞–º–∏
                    center1 = det['center']
                    bbox = track_data['bbox']
                    center2 = [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]
                    distance = np.sqrt((center1[0] - center2[0]) ** 2 + (center1[1] - center2[1]) ** 2)

                    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –µ—Å–ª–∏ –µ—Å—Ç—å
                    feature_sim = 0
                    if det['features'] is not None and 'features' in track_data:
                        feature_sim = self._compare_features(det['features'], track_data['features'])

                    # –û–±—â–∏–π score
                    score = 0.4 * min(1, 1 - distance / 100) + 0.4 * iou + 0.2 * feature_sim

                    similarity_matrix.append((i, track_id, score))

            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ score
            similarity_matrix.sort(key=lambda x: x[2], reverse=True)

            # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º
            for i, track_id, score in similarity_matrix:
                if score > 0.3 and i not in matched_detections and track_id not in matched_tracks:
                    current_detections[i]['track_id'] = track_id
                    result.append(current_detections[i])
                    matched_detections.add(i)
                    matched_tracks.add(track_id)

        # 2. –ü—Ä–æ–±—É–µ–º —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å —Å –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Ç—Ä–µ–∫–∞–º–∏ (–Ω–µ–¥–∞–≤–Ω–æ –≤—ã—à–µ–¥—à–∏–º–∏)
        for i, det in enumerate(current_detections):
            if i not in matched_detections and det['features'] is not None:
                best_match = None
                best_score = 0

                for track_id, track_data in self.inactive_tracks.items():
                    if 'features' in track_data:
                        score = self._compare_features(det['features'], track_data['features'])
                        if score > self.reid_threshold and score > best_score:
                            best_score = score
                            best_match = track_id

                if best_match:
                    # –í–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –∏–∑–≤–µ—Å—Ç–Ω–æ–≥–æ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è!
                    det['track_id'] = best_match
                    result.append(det)
                    matched_detections.add(i)

                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤ –∞–∫—Ç–∏–≤–Ω—ã–µ
                    self.active_tracks[best_match] = self.inactive_tracks[best_match]
                    self.active_tracks[best_match]['last_seen'] = time.time()
                    self.active_tracks[best_match]['age'] += 1
                    self.active_tracks[best_match]['visit_count'] = self.active_tracks[best_match].get('visit_count',
                                                                                                       0) + 1

                    # –£–¥–∞–ª—è–µ–º –∏–∑ –Ω–µ–∞–∫—Ç–∏–≤–Ω—ã—Ö
                    if best_match in self.inactive_tracks:
                        del self.inactive_tracks[best_match]

                    print(f"üîÑ –í–æ–∑–≤—Ä–∞—â–µ–Ω–∏–µ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—è ID: {best_match} (—Å—Ö–æ–∂–µ—Å—Ç—å: {best_score:.2f})")

        # 3. –ù–æ–≤—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ (–Ω–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ)
        for i, det in enumerate(current_detections):
            if i not in matched_detections:
                det['track_id'] = self._get_new_track_id()
                result.append(det)

        return result

    def _compute_iou(self, box1, box2):
        """–í—ã—á–∏—Å–ª—è–µ—Ç IoU"""
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2

        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)

        inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)
        box1_area = (x1_max - x1_min) * (y1_max - y1_min)
        box2_area = (x2_max - x2_min) * (y2_max - y2_min)

        return inter_area / (box1_area + box2_area - inter_area + 1e-10)

    def _get_new_track_id(self):
        """–ù–æ–≤—ã–π ID —Ç—Ä–µ–∫–∞"""
        track_id = self.next_track_id
        self.next_track_id += 1
        return track_id

    def _draw_detections(self, frame, detections):
        """–†–∏—Å—É–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ —Ü–≤–µ—Ç–∞–º–∏ –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö/–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö"""
        for det in detections:
            bbox = det['bbox']
            track_id = det['track_id']
            confidence = det['confidence']
            age = det.get('age', 1)
            is_known = det.get('is_known', False)

            x1, y1, x2, y2 = map(int, bbox)

            # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
            if is_known:
                color = (255, 0, 255)  # —Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π –¥–ª—è –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö
                label = f"KNOWN {track_id}"
            elif age < 20:
                color = (0, 165, 255)  # –æ—Ä–∞–Ω–∂–µ–≤—ã–π –¥–ª—è –Ω–æ–≤—ã—Ö
                label = f"NEW {track_id}"
            else:
                color = (0, 255, 0)  # –∑–µ–ª–µ–Ω—ã–π –¥–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö
                label = f"ID {track_id}"

            # –ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)

            # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            text_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(frame, (x1, y1 - text_size[1] - 10),
                          (x1 + text_size[0], y1), color, -1)

            # –¢–µ–∫—Å—Ç
            cv2.putText(frame, label, (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            info_text = f"{confidence:.0%}"
            if age > 1:
                info_text += f" ({age}f)"
            cv2.putText(frame, info_text, (x1, y2 + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        known_count = sum(1 for d in detections if d.get('is_known', False))
        stats_text = f"–õ—é–¥–µ–π: {len(detections)} | –ò–∑–≤–µ—Å—Ç–Ω—ã—Ö: {known_count} | –í—Å–µ–≥–æ –≤ –ø–∞–º—è—Ç–∏: {len(self.known_visitors)}"
        cv2.putText(frame, stats_text, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        # –í—Ä–µ–º—è
        time_text = datetime.now().strftime("%H:%M:%S")
        cv2.putText(frame, time_text, (frame.shape[1] - 120, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        # –ü–æ–¥—Å–∫–∞–∑–∫–∞ –ø–æ —Ü–≤–µ—Ç–∞–º
        legend_y = 60
        legends = [
            ("üü£ –ò–∑–≤–µ—Å—Ç–Ω—ã–π –ø–æ—Å–µ—Ç–∏—Ç–µ–ª—å", (255, 0, 255)),
            ("üü† –ù–æ–≤—ã–π (–º–µ–Ω–µ–µ 20 –∫–∞–¥—Ä–æ–≤)", (0, 165, 255)),
            ("üü¢ –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π", (0, 255, 0))
        ]

        for text, color in legends:
            cv2.putText(frame, text, (10, legend_y),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            legend_y += 20

    def get_current_frame(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä"""
        if not self.processed_queue.empty():
            return self.processed_queue.get()
        return None

    def get_statistics(self):
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        known_active = sum(1 for t in self.active_tracks.values() if t.get('is_known', False))

        return {
            'current_count': self.current_count,
            'today_unique': len(self.today_unique),
            'session_unique': len(self.session_unique),
            'known_visitors': len(self.known_visitors),
            'known_active': known_active,
            'active_tracks': len(self.active_tracks),
            'inactive_tracks': len(self.inactive_tracks),
            'total_visitors': len(self.visitor_history)
        }

    def get_visitor_details(self, limit=20):
        """–ü–æ–ª—É—á–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π"""
        visitors = []
        current_time = time.time()

        for track_id, data in list(self.active_tracks.items())[:limit]:
            visitors.append({
                'id': track_id,
                'age': data['age'],
                'is_known': data.get('is_known', False),
                'visit_count': data.get('visit_count', 1),
                'time_in_frame': current_time - data.get('first_seen', current_time)
            })

        return visitors

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞"""
        self.running = False
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        self._save_visitors_db()
        if self.cap:
            self.cap.release()
        print("‚úì –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")