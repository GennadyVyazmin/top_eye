# /top_eye/src/core/video_processor_occlusion.py
import cv2
import torch
import numpy as np
from threading import Thread, Lock
from queue import Queue
from datetime import datetime
import time
import os
import pickle
import hashlib
from collections import deque, defaultdict
import json


class VideoProcessor:
    def __init__(self, config):
        self.config = config
        print(f"–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –¥–ª—è –∫–∞–º–µ—Ä—ã: {config.CAMERA_ID}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã
        self.cap = None
        self.last_reconnect = time.time()
        self.reconnect_interval = 5

        # –û—á–µ—Ä–µ–¥–∏
        self.frame_queue = Queue(maxsize=15)
        self.processed_queue = Queue(maxsize=15)
        self.lock = Lock()
        self.running = False

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.current_count = 0
        self.today_unique = set()
        self.session_unique = set()
        self.visitor_history = {}
        self.total_visitors = 0

        # –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —Å –æ–∫–∫–ª—é–∑–∏—è–º–∏
        self.active_tracks = {}  # {track_id: TrackObject}
        self.occluded_tracks = {}  # –¢—Ä–µ–∫–∏ –≤ –æ–∫–∫–ª—é–∑–∏–∏
        self.group_manager = GroupManager()  # –ú–µ–Ω–µ–¥–∂–µ—Ä –≥—Ä—É–ø–ø
        self.next_track_id = 1000

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        self.max_occlusion_time = 45  # –∫–∞–¥—Ä–æ–≤ (1.5 —Å–µ–∫ –ø—Ä–∏ 30 FPS)
        self.occlusion_threshold = 0.3  # –ø–æ—Ä–æ–≥ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏—è –¥–ª—è –æ–∫–∫–ª—é–∑–∏–∏
        self.group_threshold = 50  # —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –≤ –≥—Ä—É–ø–ø—É

        # YOLO –º–æ–¥–µ–ª—å
        self.model = None

        # –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö
        self.visitors_db_path = "data/visitors_advanced.db"
        self._load_visitors_db()

        # –ò—Å—Ç–æ—Ä–∏—è –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è
        self.track_history = defaultdict(lambda: deque(maxlen=10))

        print("‚úì –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ–∫–∫–ª—é–∑–∏–π")

    def _load_visitors_db(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if os.path.exists(self.visitors_db_path):
                with open(self.visitors_db_path, 'rb') as f:
                    data = pickle.load(f)
                    self.visitor_history = data.get('visitor_history', {})
                    self.next_track_id = data.get('next_track_id', 1000)
                print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –∏—Å—Ç–æ—Ä–∏—è {len(self.visitor_history)} –ø–æ—Å–µ—Ç–∏—Ç–µ–ª–µ–π")
        except:
            print("‚ö† –ù–æ–≤–∞—è –±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö")
            self.visitor_history = {}

    def _save_visitors_db(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        try:
            os.makedirs(os.path.dirname(self.visitors_db_path), exist_ok=True)
            data = {
                'visitor_history': self.visitor_history,
                'next_track_id': self.next_track_id,
                'saved_at': datetime.now().isoformat()
            }
            with open(self.visitors_db_path, 'wb') as f:
                pickle.dump(data, f)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

    def init_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"""
        try:
            print("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")

            from ultralytics import YOLO
            model_path = self.config.YOLO_MODEL_PATH

            if not os.path.exists(model_path):
                print("–°–∫–∞—á–∏–≤–∞–µ–º YOLOv8n...")
                model_path = 'yolov8n.pt'

            self.model = YOLO(model_path)
            self.model.to('cuda' if torch.cuda.is_available() else 'cpu')
            print(f"‚úì YOLO –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {'CUDA' if torch.cuda.is_available() else 'CPU'}")

            print("‚úì –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —Ç—Ä–µ–∫–∏–Ω–≥ —Å –æ–∫–∫–ª—é–∑–∏—è–º–∏")

        except Exception as e:
            print(f"‚úó –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")

    def start(self):
        """–ó–∞–ø—É—Å–∫"""
        self.running = True
        self.init_models()
        Thread(target=self._capture_frames, daemon=True).start()
        Thread(target=self._process_frames, daemon=True).start()
        Thread(target=self._manage_tracks, daemon=True).start()
        print("‚úì –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞")

    def _capture_frames(self):
        """–ó–∞—Ö–≤–∞—Ç –∫–∞–¥—Ä–æ–≤"""
        frame_count = 0

        while self.running:
            try:
                if self.cap is None or not self.cap.isOpened():
                    if time.time() - self.last_reconnect > self.reconnect_interval:
                        print("–ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ...")
                        self._reconnect_camera()
                        time.sleep(1)
                        continue
                    else:
                        time.sleep(0.1)
                        continue

                success, frame = self.cap.read()

                if not success:
                    print("‚úó –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
                    self.cap.release()
                    self.cap = None
                    continue

                if frame_count % self.config.PROCESS_EVERY_N_FRAMES == 0:
                    if not self.frame_queue.full():
                        self.frame_queue.put(frame.copy())

                frame_count += 1
                time.sleep(0.01)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∑–∞—Ö–≤–∞—Ç–∞: {e}")
                if self.cap:
                    self.cap.release()
                self.cap = None
                time.sleep(1)

    def _reconnect_camera(self):
        """–ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ"""
        try:
            if self.cap:
                self.cap.release()

            print(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫: {self.config.RTSP_URL}")
            self.cap = cv2.VideoCapture(self.config.RTSP_URL)
            self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 2)
            self.cap.set(cv2.CAP_PROP_FPS, self.config.FPS)

            time.sleep(0.5)

            if self.cap.isOpened():
                print("‚úì –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞")
                self.last_reconnect = time.time()
                return True
            else:
                print("‚úó –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è")
                return False

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {e}")
            return False

    def _process_frames(self):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤"""
        while self.running:
            try:
                if not self.frame_queue.empty():
                    frame = self.frame_queue.get()
                    processed_data = self._process_single_frame(frame)

                    if not self.processed_queue.full():
                        self.processed_queue.put(processed_data)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

    def _manage_tracks(self):
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–∫–∞–º–∏ –∏ –æ–∫–∫–ª—é–∑–∏—è–º–∏"""
        while self.running:
            try:
                current_time = time.time()

                # –û–±–Ω–æ–≤–ª—è–µ–º –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏
                occluded_to_remove = []
                for track_id, track_data in list(self.occluded_tracks.items()):
                    if current_time - track_data['occluded_since'] > self.max_occlusion_time / 30:
                        occluded_to_remove.append(track_id)

                for track_id in occluded_to_remove:
                    del self.occluded_tracks[track_id]

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞–∑—É –∫–∞–∂–¥—ã–µ 2 –º–∏–Ω—É—Ç—ã
                if int(current_time) % 120 == 0:
                    self._save_visitors_db()

                time.sleep(0.5)

            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ç—Ä–µ–∫–∞–º–∏: {e}")
                time.sleep(2)

    def _process_single_frame(self, frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ —Å —É—á–µ—Ç–æ–º –æ–∫–∫–ª—é–∑–∏–π"""
        result = {
            'frame': frame.copy(),
            'detections': [],
            'occluded': [],
            'timestamp': datetime.now(),
            'people_count': 0,
            'occluded_count': 0,
            'fps': 0
        }

        try:
            if self.model is not None:
                start_time = time.time()

                # –î–µ—Ç–µ–∫—Ü–∏—è
                with torch.no_grad():
                    yolo_results = self.model(
                        frame,
                        conf=self.config.CONFIDENCE_THRESHOLD,
                        device='cuda' if torch.cuda.is_available() else 'cpu',
                        verbose=False,
                        classes=[0]
                    )

                # –¢–µ–∫—É—â–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
                current_detections = []
                if yolo_results and len(yolo_results) > 0:
                    yolo_result = yolo_results[0]

                    if yolo_result.boxes is not None and len(yolo_result.boxes) > 0:
                        boxes = yolo_result.boxes.xyxy.cpu().numpy()
                        confidences = yolo_result.boxes.conf.cpu().numpy()

                        for i in range(len(boxes)):
                            x1, y1, x2, y2 = boxes[i].astype(int)
                            conf = float(confidences[i])

                            width = x2 - x1
                            height = y2 - y1

                            if width > 30 and height > 60:
                                person_roi = frame[y1:y2, x1:x2]
                                appearance_hash = self._get_appearance_hash(person_roi)

                                current_detections.append({
                                    'bbox': [float(x1), float(y1), float(x2), float(y2)],
                                    'center': [(x1 + x2) / 2, (y1 + y2) / 2],
                                    'confidence': conf,
                                    'width': width,
                                    'height': height,
                                    'appearance_hash': appearance_hash,
                                    'area': width * height
                                })

                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–∫–∫–ª—é–∑–∏–π
                processed_detections = self._handle_occlusions(current_detections)

                # –û–±–Ω–æ–≤–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏
                current_time = time.time()
                for det in processed_detections:
                    track_id = det['track_id']
                    is_occluded = det.get('is_occluded', False)

                    if is_occluded:
                        # –¢—Ä–µ–∫ –≤ –æ–∫–∫–ª—é–∑–∏–∏
                        if track_id not in self.occluded_tracks:
                            self.occluded_tracks[track_id] = {
                                'last_bbox': det['bbox'],
                                'occluded_since': current_time,
                                'appearance_hash': det['appearance_hash']
                            }
                    else:
                        # –ê–∫—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–∫
                        if track_id not in self.active_tracks:
                            self.active_tracks[track_id] = {
                                'bbox': det['bbox'],
                                'last_seen': current_time,
                                'first_seen': current_time,
                                'appearance_hash': det['appearance_hash'],
                                'age': 1,
                                'occlusion_count': 0,
                                'velocity': [0, 0]
                            }
                        else:
                            # –û–±–Ω–æ–≤–ª—è–µ–º —Å –ø—Ä–æ–≥–Ω–æ–∑–æ–º –¥–≤–∏–∂–µ–Ω–∏—è
                            old_bbox = self.active_tracks[track_id]['bbox']
                            new_bbox = det['bbox']

                            # –ü—Ä–æ–≥–Ω–æ–∑ –ø–æ–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–æ—Ä–æ—Å—Ç–∏
                            velocity = self.active_tracks[track_id]['velocity']
                            predicted_bbox = self._predict_bbox(old_bbox, velocity)

                            # –°–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ
                            smoothed_bbox = self._smooth_bbox(old_bbox, new_bbox, predicted_bbox)

                            # –û–±–Ω–æ–≤–ª—è–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å
                            dx = (smoothed_bbox[0] - old_bbox[0] + smoothed_bbox[2] - old_bbox[2]) / 2
                            dy = (smoothed_bbox[1] - old_bbox[1] + smoothed_bbox[3] - old_bbox[3]) / 2
                            velocity = [velocity[0] * 0.7 + dx * 0.3,
                                        velocity[1] * 0.7 + dy * 0.3]

                            self.active_tracks[track_id].update({
                                'bbox': smoothed_bbox,
                                'last_seen': current_time,
                                'appearance_hash': det['appearance_hash'],
                                'age': self.active_tracks[track_id]['age'] + 1,
                                'velocity': velocity
                            })

                        # –î–æ–±–∞–≤–ª—è–µ–º –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        result['detections'].append({
                            'track_id': track_id,
                            'bbox': self.active_tracks[track_id]['bbox'],
                            'confidence': det['confidence'],
                            'age': self.active_tracks[track_id]['age'],
                            'velocity': self.active_tracks[track_id]['velocity']
                        })

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏
                for track_id, track_data in self.occluded_tracks.items():
                    # –ü—Ä–æ–±—É–µ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏
                    restored = self._try_restore_occluded(track_id, current_detections)
                    if not restored:
                        result['occluded'].append({
                            'track_id': track_id,
                            'last_bbox': track_data['last_bbox'],
                            'occluded_since': track_data['occluded_since']
                        })

                # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                result['people_count'] = len(result['detections'])
                result['occluded_count'] = len(result['occluded'])
                self.current_count = result['people_count']

                # –û–±–Ω–æ–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö
                for det in result['detections']:
                    track_id = det['track_id']
                    if self.active_tracks[track_id]['age'] > 10:
                        self.session_unique.add(track_id)
                        today = datetime.now().date().isoformat()
                        self.today_unique.add(f"{today}_{track_id}")

                # FPS
                end_time = time.time()
                result['fps'] = 1.0 / (end_time - start_time) if (end_time - start_time) > 0 else 0

                # –†–∏—Å—É–µ–º
                self._draw_detections(frame, result['detections'], result['occluded'])

        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")

        return result

    def _handle_occlusions(self, current_detections):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–∫–∫–ª—é–∑–∏–π –∏ –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è"""
        processed = []

        if not current_detections:
            return processed

        # 1. –ê–Ω–∞–ª–∏–∑ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π
        intersections = self._analyze_intersections(current_detections)

        # 2. –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –±–ª–∏–∑–∫–∏—Ö –¥–µ—Ç–µ–∫—Ü–∏–π
        groups = self._group_detections(current_detections)

        # 3. –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å –∞–∫—Ç–∏–≤–Ω—ã–º–∏ —Ç—Ä–µ–∫–∞–º–∏ —Å —É—á–µ—Ç–æ–º –≥—Ä—É–ø–ø
        matched_detections = set()
        matched_tracks = set()

        if self.active_tracks:
            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞ –∏—â–µ–º –ª—É—á—à—É—é –¥–µ—Ç–µ–∫—Ü–∏—é
            for track_id, track_data in self.active_tracks.items():
                best_det_idx = -1
                best_score = 0

                for i, det in enumerate(current_detections):
                    if i in matched_detections:
                        continue

                    # –£—á–µ—Ç –æ–∫–∫–ª—é–∑–∏–∏
                    is_occluded = self._check_occlusion(det['bbox'], intersections)

                    # Score —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤
                    score = self._compute_occlusion_score(
                        det, track_data, is_occluded, groups
                    )

                    if score > best_score and score > 0.3:
                        best_score = score
                        best_det_idx = i

                if best_det_idx != -1:
                    # –°–æ–ø–æ—Å—Ç–∞–≤–ª—è–µ–º
                    det = current_detections[best_det_idx]
                    det['track_id'] = track_id
                    det['is_occluded'] = self._check_occlusion(det['bbox'], intersections)
                    processed.append(det)

                    matched_detections.add(best_det_idx)
                    matched_tracks.add(track_id)

        # 4. –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–∑ –æ–∫–∫–ª—é–∑–∏–π
        for track_id, track_data in list(self.occluded_tracks.items()):
            if track_id in matched_tracks:
                continue

            best_det_idx = -1
            best_score = 0

            for i, det in enumerate(current_detections):
                if i in matched_detections:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å —Å –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç—Ä–µ–∫–æ–º
                score = self._compare_with_occluded(det, track_data)

                if score > best_score and score > 0.5:
                    best_score = score
                    best_det_idx = i

            if best_det_idx != -1:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç—Ä–µ–∫
                det = current_detections[best_det_idx]
                det['track_id'] = track_id
                det['is_occluded'] = False
                processed.append(det)

                matched_detections.add(best_det_idx)

                # –ü–µ—Ä–µ–º–µ—â–∞–µ–º –∏–∑ –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤ –∞–∫—Ç–∏–≤–Ω—ã–µ
                self.active_tracks[track_id] = {
                    'bbox': det['bbox'],
                    'last_seen': time.time(),
                    'first_seen': time.time(),
                    'appearance_hash': det['appearance_hash'],
                    'age': track_data.get('age', 0) + 1,
                    'occlusion_count': track_data.get('occlusion_count', 0),
                    'velocity': [0, 0]
                }
                del self.occluded_tracks[track_id]

                print(f"üîÑ –í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω —Ç—Ä–µ–∫ {track_id} –ø–æ—Å–ª–µ –æ–∫–∫–ª—é–∑–∏–∏")

        # 5. –ù–æ–≤—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
        for i, det in enumerate(current_detections):
            if i not in matched_detections:
                track_id = self._get_new_track_id()
                det['track_id'] = track_id
                det['is_occluded'] = self._check_occlusion(det['bbox'], intersections)
                processed.append(det)

        return processed

    def _analyze_intersections(self, detections):
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è –º–µ–∂–¥—É bounding boxes"""
        intersections = []
        n = len(detections)

        for i in range(n):
            for j in range(i + 1, n):
                iou = self._compute_iou(detections[i]['bbox'], detections[j]['bbox'])
                if iou > self.occlusion_threshold:
                    intersections.append({
                        'det1_idx': i,
                        'det2_idx': j,
                        'iou': iou,
                        'center_dist': self._compute_distance(
                            detections[i]['center'], detections[j]['center']
                        )
                    })

        return intersections

    def _group_detections(self, detections):
        """–ì—Ä—É–ø–ø–∏—Ä—É–µ—Ç –±–ª–∏–∑–∫–æ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–Ω—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        groups = []
        n = len(detections)
        visited = [False] * n

        for i in range(n):
            if not visited[i]:
                group = [i]
                visited[i] = True

                # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ—Ö –±–ª–∏–∑–∫–∏—Ö —Å–æ—Å–µ–¥–µ–π
                queue = [i]
                while queue:
                    current = queue.pop(0)
                    for j in range(n):
                        if not visited[j]:
                            dist = self._compute_distance(
                                detections[current]['center'],
                                detections[j]['center']
                            )
                            if dist < self.group_threshold:
                                group.append(j)
                                visited[j] = True
                                queue.append(j)

                if len(group) > 1:
                    groups.append(group)

        return groups

    def _compute_occlusion_score(self, det, track_data, is_occluded, groups):
        """–í—ã—á–∏—Å–ª—è–µ—Ç score –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å —É—á–µ—Ç–æ–º –æ–∫–∫–ª—é–∑–∏–π"""
        score = 0

        # 1. –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ (–æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–∫—Ç–æ—Ä)
        center1 = det['center']
        bbox = track_data['bbox']
        center2 = [(bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2]
        distance = self._compute_distance(center1, center2)

        # –£—á–∏—Ç—ã–≤–∞–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞
        velocity = track_data.get('velocity', [0, 0])
        predicted_center = [center2[0] + velocity[0], center2[1] + velocity[1]]
        predicted_distance = self._compute_distance(center1, predicted_center)

        distance_score = max(0, 1 - min(distance, predicted_distance) / 100)
        score += 0.5 * distance_score

        # 2. –í–∏–∑—É–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
        if det['appearance_hash'] and track_data.get('appearance_hash'):
            hash_sim = self._compare_hashes(det['appearance_hash'],
                                            track_data['appearance_hash'])
            score += 0.3 * hash_sim

        # 3. –£—á–µ—Ç –≥—Ä—É–ø–ø
        group_bonus = self._get_group_bonus(det, track_data, groups)
        score += 0.2 * group_bonus

        # 4. –®—Ç—Ä–∞—Ñ –∑–∞ –æ–∫–∫–ª—é–∑–∏—é
        if is_occluded:
            score *= 0.8  # –®—Ç—Ä–∞—Ñ—É–µ–º –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ

        return score

    def _check_occlusion(self, bbox, intersections):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ –¥–µ—Ç–µ–∫—Ü–∏—è –≤ –æ–∫–∫–ª—é–∑–∏–∏"""
        for inter in intersections:
            # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
            if inter['iou'] > 0.5:
                return True
        return False

    def _compare_with_occluded(self, det, track_data):
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Å –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º —Ç—Ä–µ–∫–æ–º"""
        score = 0

        # –†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–π –∏–∑–≤–µ—Å—Ç–Ω–æ–π –ø–æ–∑–∏—Ü–∏–∏
        last_bbox = track_data.get('last_bbox', [0, 0, 0, 0])
        last_center = [(last_bbox[0] + last_bbox[2]) / 2,
                       (last_bbox[1] + last_bbox[3]) / 2]

        distance = self._compute_distance(det['center'], last_center)
        distance_score = max(0, 1 - distance / 150)
        score += 0.6 * distance_score

        # –í–∏–∑—É–∞–ª—å–Ω–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
        if det['appearance_hash'] and track_data.get('appearance_hash'):
            hash_sim = self._compare_hashes(det['appearance_hash'],
                                            track_data['appearance_hash'])
            score += 0.4 * hash_sim

        return score

    def _try_restore_occluded(self, track_id, current_detections):
        """–ü—ã—Ç–∞–µ—Ç—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç—Ä–µ–∫"""
        track_data = self.occluded_tracks.get(track_id)
        if not track_data:
            return False

        for det in current_detections:
            score = self._compare_with_occluded(det, track_data)
            if score > 0.6:  # –í—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
                return True

        return False

    def _predict_bbox(self, bbox, velocity):
        """–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç bbox –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–∫–æ—Ä–æ—Å—Ç–∏"""
        x1, y1, x2, y2 = bbox
        dx, dy = velocity
        return [x1 + dx, y1 + dy, x2 + dx, y2 + dy]

    def _smooth_bbox(self, old_bbox, new_bbox, predicted_bbox):
        """–°–≥–ª–∞–∂–∏–≤–∞–µ—Ç bbox"""
        alpha = 0.7  # –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è

        smoothed = []
        for o, n, p in zip(old_bbox, new_bbox, predicted_bbox):
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –Ω–æ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –∏ –ø—Ä–æ–≥–Ω–æ–∑–∞
            value = alpha * n + (1 - alpha) * p
            smoothed.append(value)

        return smoothed

    def _get_group_bonus(self, det, track_data, groups):
        """–í—ã—á–∏—Å–ª—è–µ—Ç –±–æ–Ω—É—Å –∑–∞ –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –≤ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø–µ"""
        # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –ª–æ–≥–∏–∫—É –¥–ª—è –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è
        # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –¥–≤–∞ —á–µ–ª–æ–≤–µ–∫–∞ –¥–≤–∏–∂—É—Ç—Å—è –≤–º–µ—Å—Ç–µ, –æ–Ω–∏ –º–æ–≥—É—Ç —Å–æ—Ö—Ä–∞–Ω—è—Ç—å —Å–≤–æ–∏ ID
        return 0.5  # –§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –±–æ–Ω—É—Å

    def _get_appearance_hash(self, image):
        """–í–∏–∑—É–∞–ª—å–Ω—ã–π —Ö–µ—à"""
        if image is None or image.size == 0:
            return "0"

        try:
            resized = cv2.resize(image, (32, 64))
            gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)

            # –ü—Ä–æ—Å—Ç–æ–π —Ö–µ—à –Ω–∞ –æ—Å–Ω–æ–≤–µ —è—Ä–∫–æ—Å—Ç–∏
            avg = np.mean(gray)
            binary = (gray > avg).flatten()
            return ''.join(['1' if b else '0' for b in binary])
        except:
            return "0"

    def _compare_hashes(self, hash1, hash2):
        """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –¥–≤–∞ —Ö–µ—à–∞"""
        if len(hash1) != len(hash2):
            return 0

        matches = sum(1 for a, b in zip(hash1, hash2) if a == b)
        return matches / len(hash1)

    def _compute_iou(self, box1, box2):
        """IoU"""
        x1_min, y1_min, x1_max, y1_max = box1
        x2_min, y2_min, x2_max, y2_max = box2

        inter_x_min = max(x1_min, x2_min)
        inter_y_min = max(y1_min, y2_min)
        inter_x_max = min(x1_max, x2_max)
        inter_y_max = min(y1_max, y2_max)

        inter_area = max(0, inter_x_max - inter_x_min) * max(0, inter_y_max - inter_y_min)
        box1_area = (x1_max - x1_min) * (y1_max - y1_min)
        box2_area = (x2_max - x2_min) * (y2_max - y2_min)

        return inter_area / (box1_area + box2_area - inter_area + 1e-10)

    def _compute_distance(self, point1, point2):
        """–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏"""
        return np.sqrt((point1[0] - point2[0]) ** 2 + (point1[1] - point2[1]) ** 2)

    def _get_new_track_id(self):
        """–ù–æ–≤—ã–π ID"""
        track_id = self.next_track_id
        self.next_track_id += 1
        return track_id

    def _draw_detections(self, frame, detections, occluded):
        """–†–∏—Å—É–µ—Ç –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ–∫–∫–ª—é–∑–∏–π"""
        # –ê–∫—Ç–∏–≤–Ω—ã–µ —Ç—Ä–µ–∫–∏
        for det in detections:
            bbox = det['bbox']
            track_id = det['track_id']
            age = det.get('age', 1)
            velocity = det.get('velocity', [0, 0])

            x1, y1, x2, y2 = map(int, bbox)

            # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–æ–∑—Ä–∞—Å—Ç–∞ –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
            speed = np.sqrt(velocity[0] ** 2 + velocity[1] ** 2)

            if speed < 2:
                color = (0, 255, 0)  # –∑–µ–ª–µ–Ω—ã–π - –Ω–µ–ø–æ–¥–≤–∏–∂–Ω—ã–π
                status = "STABLE"
            elif speed < 10:
                color = (0, 255, 255)  # –∂–µ–ª—Ç—ã–π - –¥–≤–∏–∂–µ—Ç—Å—è
                status = "MOVING"
            else:
                color = (0, 0, 255)  # –∫—Ä–∞—Å–Ω—ã–π - –±—ã—Å—Ç—Ä–æ –¥–≤–∏–∂–µ—Ç—Å—è
                status = "FAST"

            # –ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∏–∫
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)

            # ID –∏ —Å—Ç–∞—Ç—É—Å
            text = f"ID: {track_id} ({status})"
            text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 2)[0]
            cv2.rectangle(frame, (x1, y1 - text_size[1] - 10),
                          (x1 + text_size[0], y1), color, -1)
            cv2.putText(frame, text, (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

            # –í–æ–∑—Ä–∞—Å—Ç —Ç—Ä–µ–∫–∞
            age_text = f"Age: {age}f"
            cv2.putText(frame, age_text, (x1, y2 + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, color, 1)

        # –û–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç—Ä–µ–∫–∏ (–ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–µ)
        for occ in occluded:
            bbox = occ['last_bbox']
            track_id = occ['track_id']
            occluded_time = time.time() - occ['occluded_since']

            x1, y1, x2, y2 = map(int, bbox)

            # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π –∫—Ä–∞—Å–Ω—ã–π –¥–ª—è –æ–∫–∫–ª—é–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö
            overlay = frame.copy()
            cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 0, 255), 2)
            cv2.addWeighted(overlay, 0.3, frame, 0.7, 0, frame)

            # –¢–µ–∫—Å—Ç
            text = f"OCC: {track_id}"
            cv2.putText(frame, text, (x1, y1 - 5),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

            # –í—Ä–µ–º—è –æ–∫–∫–ª—é–∑–∏–∏
            time_text = f"{occluded_time:.1f}s"
            cv2.putText(frame, time_text, (x1, y2 + 20),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)

        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats_text = f"–ê–∫—Ç–∏–≤–Ω—ã—Ö: {len(detections)} | –û–∫–∫–ª—é–∑–∏–π: {len(occluded)} | –í—Å–µ–≥–æ —Ç—Ä–µ–∫–æ–≤: {len(self.active_tracks) + len(self.occluded_tracks)}"
        cv2.putText(frame, stats_text, (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

        # –õ–µ–≥–µ–Ω–¥–∞
        legend = [
            ("üü¢ –ù–µ–ø–æ–¥–≤–∏–∂–Ω—ã–π", (0, 255, 0)),
            ("üü° –î–≤–∏–∂–µ—Ç—Å—è", (0, 255, 255)),
            ("üî¥ –ë—ã—Å—Ç—Ä–æ –¥–≤–∏–∂–µ—Ç—Å—è", (0, 0, 255)),
            ("‚ö´ –û–∫–∫–ª—é–∑–∏—è", (0, 0, 255))
        ]

        y_offset = 60
        for text, color in legend:
            cv2.putText(frame, text, (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)
            y_offset += 20

    def get_current_frame(self):
        """–ü–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä"""
        if not self.processed_queue.empty():
            return self.processed_queue.get()
        return None

    def get_statistics(self):
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞"""
        return {
            'current_count': self.current_count,
            'today_unique': len(self.today_unique),
            'session_unique': len(self.session_unique),
            'active_tracks': len(self.active_tracks),
            'occluded_tracks': len(self.occluded_tracks),
            'total_visitors': len(self.visitor_history)
        }

    def stop(self):
        """–û—Å—Ç–∞–Ω–æ–≤–∫–∞"""
        self.running = False
        self._save_visitors_db()
        if self.cap:
            self.cap.release()
        print("‚úì –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞")


class GroupManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –≥—Ä—É–ø–ø–æ–≤–æ–≥–æ –¥–≤–∏–∂–µ–Ω–∏—è"""

    def __init__(self):
        self.groups = {}  # {group_id: [track_ids]}
        self.next_group_id = 1

    def update_groups(self, detections):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –≥—Ä—É–ø–ø—ã"""
        # –ü—Ä–æ—Å—Ç–∞—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é
        groups = []
        visited = set()

        for i, det1 in enumerate(detections):
            if i in visited:
                continue

            group = [i]
            visited.add(i)

            for j, det2 in enumerate(detections):
                if j in visited:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                dist = np.sqrt(
                    (det1['center'][0] - det2['center'][0]) ** 2 +
                    (det1['center'][1] - det2['center'][1]) ** 2
                )

                if dist < 100:  # –ü–æ—Ä–æ–≥ –¥–ª—è –≥—Ä—É–ø–ø—ã
                    group.append(j)
                    visited.add(j)

            if len(group) > 1:
                groups.append(group)

        return groups

    # –í –∫–ª–∞—Å—Å VideoProcessor –¥–æ–±–∞–≤—å—Ç–µ:

    def _use_kalman_filter(self):
        """–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ñ–∏–ª—å—Ç—Ä–∞ –ö–∞–ª–º–∞–Ω–∞ –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –§–∏–ª—å—Ç—Ä –ö–∞–ª–º–∞–Ω–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç—Ä–µ–∫–∞
        pass

    def _deep_sort_integration(self):
        """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å DeepSORT –¥–ª—è –ª—É—á—à–µ–≥–æ —Ç—Ä–µ–∫–∏–Ω–≥–∞"""