# /top_eye/src/core/face_database.py
import sqlite3
import numpy as np
import json
import os
import pickle
from datetime import datetime, timedelta
from collections import defaultdict
import hashlib


class FaceDatabase:
    """–ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–æ–ª–≥–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ —Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–∏—Ü —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π"""

    def __init__(self, db_path="data/face_database.db"):
        self.db_path = db_path
        self.conn = None
        self._init_database()

        # –ö—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞
        self.face_cache = {}  # {face_id: face_data}
        self.person_cache = defaultdict(list)  # {person_id: [face_ids]}
        self.embedding_cache = {}  # {person_id: [embeddings]}
        self.load_cache()

        print(f"üìä –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ª–∏—Ü –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞: {db_path}")
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.face_cache)} –ª–∏—Ü, {len(self.person_cache)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ª—é–¥–µ–π")

    def _init_database(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)

        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        cursor = self.conn.cursor()

        # –¢–∞–±–ª–∏—Ü–∞ –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª–∏—Ü
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS known_faces (
                face_id INTEGER PRIMARY KEY AUTOINCREMENT,
                person_id TEXT NOT NULL,
                name TEXT,
                embedding BLOB NOT NULL,
                metadata TEXT,
                first_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                visit_count INTEGER DEFAULT 1,
                total_time INTEGER DEFAULT 0,
                is_active BOOLEAN DEFAULT 1,
                confidence REAL DEFAULT 0.0,
                is_primary BOOLEAN DEFAULT 0,
                quality_score REAL DEFAULT 0.0
            )
        ''')

        # –¢–∞–±–ª–∏—Ü–∞ –¥–µ—Ç–µ–∫—Ü–∏–π (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS detections (
                detection_id INTEGER PRIMARY KEY AUTOINCREMENT,
                face_id INTEGER,
                person_id TEXT,
                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                camera_id TEXT,
                confidence REAL,
                bbox TEXT,
                embedding_hash TEXT,
                FOREIGN KEY (face_id) REFERENCES known_faces (face_id)
            )
        ''')

        # –¢–∞–±–ª–∏—Ü–∞ —Å–µ—Å—Å–∏–π
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sessions (
                session_id INTEGER PRIMARY KEY AUTOINCREMENT,
                face_id INTEGER,
                person_id TEXT,
                start_time TIMESTAMP,
                end_time TIMESTAMP,
                duration INTEGER,
                FOREIGN KEY (face_id) REFERENCES known_faces (face_id)
            )
        ''')

        # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —Å–ª–∏—è–Ω–∏–π
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS merges (
                merge_id INTEGER PRIMARY KEY AUTOINCREMENT,
                old_person_id TEXT,
                new_person_id TEXT,
                merge_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                reason TEXT
            )
        ''')

        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_face_person ON known_faces(person_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_face_active ON known_faces(is_active)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_detections_time ON detections(timestamp)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_sessions_time ON sessions(start_time)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_detections_person ON detections(person_id)')

        self.conn.commit()

    def load_cache(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ –∏–∑ –±–∞–∑—ã"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                SELECT face_id, person_id, embedding, confidence, quality_score, is_primary
                FROM known_faces 
                WHERE is_active = 1
                ORDER BY last_seen DESC
            ''')

            for row in cursor.fetchall():
                face_id, person_id, embedding_blob, confidence, quality_score, is_primary = row
                embedding = pickle.loads(embedding_blob)

                self.face_cache[face_id] = {
                    'person_id': person_id,
                    'embedding': embedding,
                    'confidence': confidence,
                    'quality_score': quality_score,
                    'is_primary': is_primary
                }

                self.person_cache[person_id].append(face_id)

                if person_id not in self.embedding_cache:
                    self.embedding_cache[person_id] = []
                self.embedding_cache[person_id].append(embedding)

            print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.face_cache)} –ª–∏—Ü, {len(self.person_cache)} –ª—é–¥–µ–π –≤ –∫—ç—à")

        except Exception as e:
            print(f"‚ö† –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫—ç—à–∞: {e}")

    def _normalize_embedding(self, embedding):
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞"""
        emb = np.array(embedding).flatten()
        norm = np.linalg.norm(emb)
        if norm > 0:
            emb = emb / norm
        return emb

    def find_similar_face(self, query_embedding, threshold=0.75, min_matches=1):
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–µ–≥–æ –ª–∏—Ü–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏"""
        if not self.face_cache:
            return None, None, 0.0

        query_emb = self._normalize_embedding(query_embedding)

        best_match_id = None
        best_person_id = None
        best_similarity = 0.0
        all_matches = []

        # –ü–µ—Ä–≤—ã–π –ø—Ä–æ—Ö–æ–¥: –±—ã—Å—Ç—Ä—ã–π –ø–æ–∏—Å–∫
        for face_id, face_data in self.face_cache.items():
            stored_emb = self._normalize_embedding(face_data['embedding'])

            similarity = np.dot(query_emb, stored_emb)

            if similarity >= threshold:
                all_matches.append({
                    'face_id': face_id,
                    'person_id': face_data['person_id'],
                    'similarity': similarity,
                    'confidence': face_data['confidence'],
                    'quality': face_data['quality_score']
                })

                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match_id = face_id
                    best_person_id = face_data['person_id']

        if not all_matches:
            return None, None, 0.0

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ª–∏ –º–∞—Ç—á–µ–π –¥–ª—è —ç—Ç–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
        person_matches = [m for m in all_matches if m['person_id'] == best_person_id]

        if len(person_matches) < min_matches:
            if best_similarity < 0.85:  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –º–æ–∂–µ—Ç –±—ã—Ç—å —Å –æ–¥–Ω–∏–º –º–∞—Ç—á–µ–º
                return None, None, 0.0

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        avg_similarity = np.mean([m['similarity'] for m in person_matches])
        max_similarity = best_similarity

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if max_similarity >= threshold and avg_similarity >= threshold - 0.1:
            print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ –ª–∏—Ü–æ: {best_person_id} "
                  f"(—Å—Ö–æ–∂–µ—Å—Ç—å: {max_similarity:.3f}, –º–∞—Ç—á–µ–π: {len(person_matches)})")

            # –û–±–Ω–æ–≤–ª—è–µ–º –≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –≤–∏–∑–∏—Ç–∞
            self.update_face(best_match_id, seen_now=True)

            return best_match_id, best_person_id, max_similarity

        return None, None, 0.0

    def add_face(self, embedding, person_id=None, name="Unknown", confidence=0.0,
                 metadata=None, quality_score=0.0, check_duplicates=True):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ –ª–∏—Ü–∞ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
            if check_duplicates:
                # –°–Ω–∞—á–∞–ª–∞ —Å –Ω–æ—Ä–º–∞–ª—å–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º
                face_id, existing_person_id, similarity = self.find_similar_face(
                    embedding, threshold=0.75, min_matches=1
                )

                if not face_id and similarity >= 0.7:  # –ï—Å–ª–∏ —Å—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–∏–º –ø–æ—Ä–æ–≥–æ–º –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω—ã—Ö –º–∞—Ç—á–µ–π
                    face_id, existing_person_id, similarity = self.find_similar_face(
                        embedding, threshold=0.85, min_matches=1
                    )

                if face_id:
                    print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω –≤–æ–∑–º–æ–∂–Ω—ã–π –¥—É–±–ª–∏–∫–∞—Ç –¥–ª—è {existing_person_id} (—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f})")

                    # –ï—Å–ª–∏ –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ
                    if similarity >= 0.9:
                        print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ {existing_person_id}")
                        self.update_face(face_id, embedding=embedding, confidence=max(confidence, similarity))
                        return face_id, existing_person_id

                    # –ï—Å–ª–∏ —Å—Ä–µ–¥–Ω—è—è —Å—Ö–æ–∂–µ—Å—Ç—å, –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏
                    elif similarity >= 0.8:
                        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –ª–∏—Ü–∞ —ç—Ç–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
                        person_faces = self.get_person_faces(existing_person_id)
                        if len(person_faces) >= 2:
                            # –£ —á–µ–ª–æ–≤–µ–∫–∞ —É–∂–µ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ª–∏—Ü, –¥–æ–≤–µ—Ä—è–µ–º –±–∞–∑–µ
                            print(f"‚úÖ –î–æ–±–∞–≤–ª—è–µ–º –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É —á–µ–ª–æ–≤–µ–∫—É {existing_person_id}")
                            new_face_id = self._add_new_face_instance(
                                embedding, existing_person_id, name, confidence,
                                metadata, quality_score, is_primary=False
                            )
                            return new_face_id, existing_person_id

            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞
            if person_id is None:
                person_id = self._generate_person_id()

            new_face_id = self._add_new_face_instance(
                embedding, person_id, name, confidence, metadata,
                quality_score, is_primary=True
            )

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–æ–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å –¥—Ä—É–≥–∏–º–∏ –ª—é–¥—å–º–∏
            self._check_new_person_for_duplicates(new_face_id, person_id)

            return new_face_id, person_id

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏—Ü–∞: {e}")
            import traceback
            traceback.print_exc()
            return None, None

    def _add_new_face_instance(self, embedding, person_id, name, confidence,
                               metadata, quality_score, is_primary):
        """–í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π –º–µ—Ç–æ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏—Ü–∞"""
        embedding_blob = pickle.dumps(embedding)

        cursor = self.conn.cursor()
        cursor.execute('''
            INSERT INTO known_faces 
            (person_id, name, embedding, metadata, confidence, last_seen, 
             quality_score, is_primary)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        ''', (person_id, name, embedding_blob,
              json.dumps(metadata) if metadata else None,
              confidence, datetime.now(), quality_score, 1 if is_primary else 0))

        face_id = cursor.lastrowid
        self.conn.commit()

        # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
        self.face_cache[face_id] = {
            'person_id': person_id,
            'embedding': embedding,
            'confidence': confidence,
            'quality_score': quality_score,
            'is_primary': is_primary
        }
        self.person_cache[person_id].append(face_id)

        if person_id not in self.embedding_cache:
            self.embedding_cache[person_id] = []
        self.embedding_cache[person_id].append(embedding)

        print(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ –ª–∏—Ü–æ: {person_id} (ID: {face_id}, –∫–∞—á–µ—Å—Ç–≤–æ: {quality_score:.2f})")

        return face_id

    def _check_new_person_for_duplicates(self, new_face_id, new_person_id):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏"""
        try:
            if new_face_id not in self.face_cache:
                return

            new_embedding = self.face_cache[new_face_id]['embedding']
            new_emb_norm = self._normalize_embedding(new_embedding)

            # –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ –ª–∏—Ü–∞ —Å—Ä–µ–¥–∏ –¥—Ä—É–≥–∏—Ö –ª—é–¥–µ–π
            for person_id, face_ids in self.person_cache.items():
                if person_id == new_person_id:
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∞–º–æ–≥–æ —Å–µ–±—è

                for face_id in face_ids:
                    if face_id in self.face_cache:
                        existing_emb = self.face_cache[face_id]['embedding']
                        existing_emb_norm = self._normalize_embedding(existing_emb)

                        similarity = np.dot(new_emb_norm, existing_emb_norm)

                        if similarity >= 0.85:  # –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
                            print(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –≤–æ–∑–º–æ–∂–Ω—ã–π –¥—É–±–ª–∏–∫–∞—Ç –º–µ–∂–¥—É {new_person_id} –∏ {person_id} "
                                  f"(—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f})")

                            # –ú–æ–∂–Ω–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –∏–ª–∏ –ø–æ–º–µ—Ç–∏—Ç—å –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                            self._mark_for_review(new_person_id, person_id, similarity)
                            break

        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã: {e}")

    def _mark_for_review(self, person1, person2, similarity):
        """–ü–æ–º–µ—Ç–∫–∞ –ø–∞—Ä—ã –ª—é–¥–µ–π –¥–ª—è —Ä—É—á–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                INSERT INTO merges (old_person_id, new_person_id, reason)
                VALUES (?, ?, ?)
            ''', (person1, person2, f"Auto-detected duplicate, similarity: {similarity:.3f}"))

            self.conn.commit()
            print(f"üìù –ü–∞—Ä–∞ {person1} - {person2} –ø–æ–º–µ—á–µ–Ω–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–º–µ—Ç–∫–∏ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {e}")

    def update_face(self, face_id, embedding=None, confidence=None, seen_now=True):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ª–∏—Ü–µ"""
        try:
            cursor = self.conn.cursor()

            updates = []
            params = []

            if embedding is not None:
                updates.append("embedding = ?")
                params.append(pickle.dumps(embedding))

                # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
                if face_id in self.face_cache:
                    self.face_cache[face_id]['embedding'] = embedding

            if confidence is not None:
                updates.append("confidence = ?")
                params.append(confidence)

                if face_id in self.face_cache:
                    self.face_cache[face_id]['confidence'] = confidence

            if seen_now:
                updates.append("last_seen = ?, visit_count = visit_count + 1")
                params.append(datetime.now())

            if updates:
                query = f"UPDATE known_faces SET {', '.join(updates)} WHERE face_id = ?"
                params.append(face_id)
                cursor.execute(query, params)
                self.conn.commit()

                print(f"üìù –û–±–Ω–æ–≤–ª–µ–Ω–æ –ª–∏—Ü–æ ID: {face_id}")

            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ª–∏—Ü–∞: {e}")
            return False

    def add_detection(self, face_id, camera_id, confidence, bbox, embedding_hash=None):
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –æ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        try:
            cursor = self.conn.cursor()

            # –ü–æ–ª—É—á–∞–µ–º person_id –¥–ª—è –ª–∏—Ü–∞
            cursor.execute('SELECT person_id FROM known_faces WHERE face_id = ?', (face_id,))
            result = cursor.fetchone()
            person_id = result[0] if result else "unknown"

            cursor.execute('''
                INSERT INTO detections (face_id, person_id, camera_id, confidence, bbox, embedding_hash)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (face_id, person_id, camera_id, confidence, json.dumps(bbox), embedding_hash))

            self.conn.commit()
            return cursor.lastrowid

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –¥–µ—Ç–µ–∫—Ü–∏–∏: {e}")
            return None

    def start_session(self, face_id, camera_id):
        """–ù–∞—á–∞–ª–æ —Å–µ—Å—Å–∏–∏ –¥–ª—è –ª–∏—Ü–∞"""
        try:
            cursor = self.conn.cursor()

            # –ü–æ–ª—É—á–∞–µ–º person_id
            cursor.execute('SELECT person_id FROM known_faces WHERE face_id = ?', (face_id,))
            result = cursor.fetchone()
            person_id = result[0] if result else "unknown"

            cursor.execute('''
                INSERT INTO sessions (face_id, person_id, start_time)
                VALUES (?, ?, ?)
            ''', (face_id, person_id, datetime.now()))

            session_id = cursor.lastrowid
            self.conn.commit()

            print(f"‚è±Ô∏è –ù–∞—á–∞—Ç–∞ —Å–µ—Å—Å–∏—è {session_id} –¥–ª—è –ª–∏—Ü–∞ {face_id}")
            return session_id

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –Ω–∞—á–∞–ª–∞ —Å–µ—Å—Å–∏–∏: {e}")
            return None

    def end_session(self, session_id):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                UPDATE sessions 
                SET end_time = ?, duration = strftime('%s', ?) - strftime('%s', start_time)
                WHERE session_id = ?
            ''', (datetime.now(), datetime.now(), session_id))

            self.conn.commit()

            print(f"‚è±Ô∏è –ó–∞–≤–µ—Ä—à–µ–Ω–∞ —Å–µ—Å—Å–∏—è {session_id}")
            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–µ—Å—Å–∏–∏: {e}")
            return False

    def deduplicate_faces(self, similarity_threshold=0.85):
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ª–∏—Ü –≤ –±–∞–∑–µ"""
        try:
            cursor = self.conn.cursor()

            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –ª–∏—Ü–∞
            cursor.execute('''
                SELECT face_id, person_id, embedding, quality_score, confidence
                FROM known_faces 
                WHERE is_active = 1
                ORDER BY person_id, quality_score DESC, confidence DESC
            ''')

            all_faces = cursor.fetchall()

            # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ person_id
            faces_by_person = defaultdict(list)
            for face_id, person_id, embedding_blob, quality_score, confidence in all_faces:
                embedding = pickle.loads(embedding_blob)
                faces_by_person[person_id].append({
                    'face_id': face_id,
                    'embedding': embedding,
                    'quality_score': quality_score,
                    'confidence': confidence
                })

            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏—Ü–∞
            faces_to_deactivate = []
            updated_primary = []

            for person_id, faces in faces_by_person.items():
                if len(faces) <= 1:
                    # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ primary –µ—Å–ª–∏ –µ—â–µ –Ω–µ –æ—Ç–º–µ—á–µ–Ω
                    if faces:
                        cursor.execute('''
                            UPDATE known_faces SET is_primary = 1 
                            WHERE face_id = ? AND is_primary = 0
                        ''', (faces[0]['face_id'],))
                        updated_primary.append(faces[0]['face_id'])
                    continue

                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–∞—á–µ—Å—Ç–≤—É
                faces.sort(key=lambda x: (x['quality_score'], x['confidence']), reverse=True)

                # –ü–µ—Ä–≤–æ–µ –ª–∏—Ü–æ –≤—Å–µ–≥–¥–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ –∏ —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è primary
                primary_face_id = faces[0]['face_id']
                unique_faces = [faces[0]]

                # –û–±–Ω–æ–≤–ª—è–µ–º primary –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
                cursor.execute('''
                    UPDATE known_faces SET is_primary = 1 
                    WHERE face_id = ? AND is_primary = 0
                ''', (primary_face_id,))
                updated_primary.append(primary_face_id)

                # –°–±—Ä–∞—Å—ã–≤–∞–µ–º primary –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö
                cursor.execute('''
                    UPDATE known_faces SET is_primary = 0 
                    WHERE person_id = ? AND face_id != ?
                ''', (person_id, primary_face_id))

                # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ª–∏—Ü–∞ —Å —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏
                for i in range(1, len(faces)):
                    current_face = faces[i]
                    is_duplicate = False

                    current_emb_norm = self._normalize_embedding(current_face['embedding'])

                    for unique_face in unique_faces:
                        unique_emb_norm = self._normalize_embedding(unique_face['embedding'])
                        similarity = np.dot(current_emb_norm, unique_emb_norm)

                        if similarity > similarity_threshold:
                            # –≠—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç
                            faces_to_deactivate.append(current_face['face_id'])
                            is_duplicate = True
                            print(f"  üóëÔ∏è –î—É–±–ª–∏–∫–∞—Ç: –ª–∏—Ü–æ {current_face['face_id']} "
                                  f"–ø–æ—Ö–æ–∂–µ –Ω–∞ {unique_face['face_id']} "
                                  f"(—Å—Ö–æ–∂–µ—Å—Ç—å: {similarity:.3f})")
                            break

                    if not is_duplicate:
                        unique_faces.append(current_face)

            # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
            if faces_to_deactivate:
                placeholders = ','.join(['?'] * len(faces_to_deactivate))
                cursor.execute(f'''
                    UPDATE known_faces 
                    SET is_active = 0, is_primary = 0
                    WHERE face_id IN ({placeholders})
                ''', faces_to_deactivate)

                # –û–±–Ω–æ–≤–ª—è–µ–º –¥–µ—Ç–µ–∫—Ü–∏–∏
                cursor.execute(f'''
                    UPDATE detections 
                    SET person_id = (
                        SELECT person_id FROM known_faces 
                        WHERE is_active = 1 AND person_id = detections.person_id 
                        LIMIT 1
                    )
                    WHERE face_id IN ({placeholders})
                ''', faces_to_deactivate)

                self.conn.commit()
                print(f"üßπ –î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ {len(faces_to_deactivate)} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤")

            if updated_primary:
                print(f"üìå –û–±–Ω–æ–≤–ª–µ–Ω–æ {len(updated_primary)} primary –ª–∏—Ü")

            # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
            self.load_cache()

            return len(faces_to_deactivate)

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: {e}")
            import traceback
            traceback.print_exc()
            return 0

    def merge_persons(self, old_person_id, new_person_id):
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –¥–≤—É—Ö –ø–µ—Ä—Å–æ–Ω"""
        try:
            cursor = self.conn.cursor()

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ª—é–¥–µ–π
            cursor.execute('SELECT COUNT(*) FROM known_faces WHERE person_id = ?', (old_person_id,))
            old_count = cursor.fetchone()[0]

            cursor.execute('SELECT COUNT(*) FROM known_faces WHERE person_id = ?', (new_person_id,))
            new_count = cursor.fetchone()[0]

            if old_count == 0 or new_count == 0:
                print(f"‚ö†Ô∏è –û–¥–∏–Ω –∏–∑ –ª—é–¥–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω: {old_person_id} ({old_count}), {new_person_id} ({new_count})")
                return False

            # –í—ã–±–∏—Ä–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ (—Ç–æ–≥–æ, —É –∫–æ–≥–æ –±–æ–ª—å—à–µ –ª–∏—Ü –∏–ª–∏ –±–æ–ª–µ–µ —Å–≤–µ–∂–∏–π)
            cursor.execute('''
                SELECT person_id, COUNT(*) as cnt, MAX(last_seen) as last_seen
                FROM known_faces 
                WHERE person_id IN (?, ?)
                GROUP BY person_id
                ORDER BY cnt DESC, last_seen DESC
                LIMIT 1
            ''', (old_person_id, new_person_id))

            result = cursor.fetchone()
            target_person_id = result[0] if result else new_person_id
            source_person_id = old_person_id if target_person_id == new_person_id else new_person_id

            # –û–±–Ω–æ–≤–ª—è–µ–º person_id –≤–æ –≤—Å–µ—Ö —Ç–∞–±–ª–∏—Ü–∞—Ö
            cursor.execute('''
                UPDATE known_faces 
                SET person_id = ? 
                WHERE person_id = ?
            ''', (target_person_id, source_person_id))

            cursor.execute('''
                UPDATE detections 
                SET person_id = ? 
                WHERE person_id = ?
            ''', (target_person_id, source_person_id))

            cursor.execute('''
                UPDATE sessions 
                SET person_id = ? 
                WHERE person_id = ?
            ''', (target_person_id, source_person_id))

            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–ª–∏—è–Ω–∏–µ
            cursor.execute('''
                INSERT INTO merges (old_person_id, new_person_id, reason)
                VALUES (?, ?, ?)
            ''', (source_person_id, target_person_id, "Manual merge"))

            self.conn.commit()

            # –û–±–Ω–æ–≤–ª—è–µ–º –∫—ç—à
            self.load_cache()

            print(f"üîó –û–±—ä–µ–¥–∏–Ω–µ–Ω—ã {source_person_id} -> {target_person_id}")

            return True

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω: {e}")
            return False

    def get_person_faces(self, person_id):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ª–∏—Ü —á–µ–ª–æ–≤–µ–∫–∞"""
        if person_id not in self.person_cache:
            return []

        faces = []
        for face_id in self.person_cache[person_id]:
            if face_id in self.face_cache:
                faces.append({
                    'face_id': face_id,
                    **self.face_cache[face_id]
                })

        return faces

    def get_statistics(self, period_hours=24):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        try:
            cursor = self.conn.cursor()

            # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
            cursor.execute('''
                SELECT 
                    COUNT(DISTINCT person_id) as total_people,
                    COUNT(*) as total_faces,
                    SUM(visit_count) as total_visits,
                    AVG(confidence) as avg_confidence
                FROM known_faces
                WHERE is_active = 1
            ''')
            total_stats = cursor.fetchone()

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥
            time_threshold = datetime.now() - timedelta(hours=period_hours)
            cursor.execute('''
                SELECT 
                    COUNT(DISTINCT d.person_id) as recent_people,
                    COUNT(*) as recent_detections
                FROM detections d
                WHERE d.timestamp > ?
            ''', (time_threshold,))
            recent_stats = cursor.fetchone()

            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –¥—É–±–ª–∏–∫–∞—Ç–∞–º
            cursor.execute('''
                SELECT 
                    person_id,
                    COUNT(*) as face_count,
                    AVG(confidence) as avg_conf,
                    MAX(last_seen) as last_seen
                FROM known_faces
                WHERE is_active = 1
                GROUP BY person_id
                HAVING COUNT(*) > 1
                ORDER BY COUNT(*) DESC
                LIMIT 10
            ''')
            duplicates_stats = cursor.fetchall()

            return {
                'total_people': total_stats[0] or 0,
                'total_faces': total_stats[1] or 0,
                'total_visits': total_stats[2] or 0,
                'avg_confidence': float(total_stats[3] or 0),
                'recent_people': recent_stats[0] or 0,
                'recent_detections': recent_stats[1] or 0,
                'duplicates': [
                    {
                        'person_id': row[0],
                        'face_count': row[1],
                        'avg_confidence': float(row[2] or 0),
                        'last_seen': row[3]
                    }
                    for row in duplicates_stats
                ]
            }

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {}

    def get_person_history(self, person_id, limit=50):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –ø–æ—Å–µ—â–µ–Ω–∏–π –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞"""
        try:
            cursor = self.conn.cursor()
            cursor.execute('''
                SELECT 
                    d.timestamp,
                    d.camera_id,
                    d.confidence,
                    d.bbox,
                    s.duration,
                    kf.name
                FROM known_faces kf
                LEFT JOIN detections d ON kf.face_id = d.face_id
                LEFT JOIN sessions s ON kf.face_id = s.face_id
                WHERE kf.person_id = ? AND kf.is_active = 1
                ORDER BY d.timestamp DESC
                LIMIT ?
            ''', (person_id, limit))

            history = cursor.fetchall()

            return [
                {
                    'timestamp': row[0],
                    'camera_id': row[1],
                    'confidence': row[2],
                    'bbox': json.loads(row[3]) if row[3] else None,
                    'duration': row[4],
                    'name': row[5]
                }
                for row in history
            ]

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏: {e}")
            return []

    def _generate_person_id(self):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ ID –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞"""
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        random_str = hashlib.md5(str(os.urandom(16)).encode()).hexdigest()[:8]
        return f"PERSON_{timestamp}_{random_str}"

    def cleanup_old_data(self, days_to_keep=30):
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            cutoff_date = datetime.now() - timedelta(days=days_to_keep)

            cursor = self.conn.cursor()

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
            cursor.execute('DELETE FROM detections WHERE timestamp < ?', (cutoff_date,))
            deleted_detections = cursor.rowcount

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–µ—Å—Å–∏–∏
            cursor.execute('DELETE FROM sessions WHERE start_time < ?', (cutoff_date,))
            deleted_sessions = cursor.rowcount

            # –î–µ–∞–∫—Ç–∏–≤–∏—Ä—É–µ–º –ª–∏—Ü–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –ø–æ—è–≤–ª—è–ª–∏—Å—å –¥–∞–≤–Ω–æ
            cursor.execute('''
                UPDATE known_faces 
                SET is_active = 0 
                WHERE last_seen < ? AND is_active = 1
            ''', (cutoff_date,))
            deactivated_faces = cursor.rowcount

            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏ –æ —Å–ª–∏—è–Ω–∏—è—Ö
            cursor.execute('DELETE FROM merges WHERE merge_time < ?', (cutoff_date,))
            deleted_merges = cursor.rowcount

            self.conn.commit()

            print(f"üßπ –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö: "
                  f"—É–¥–∞–ª–µ–Ω–æ {deleted_detections} –¥–µ—Ç–µ–∫—Ü–∏–π, "
                  f"{deleted_sessions} —Å–µ—Å—Å–∏–π, "
                  f"{deleted_merges} —Å–ª–∏—è–Ω–∏–π, "
                  f"–¥–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞–Ω–æ {deactivated_faces} –ª–∏—Ü")

            # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∫—ç—à
            self.load_cache()

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")

    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å –±–∞–∑–æ–π"""
        if self.conn:
            self.conn.close()
            print("üìÇ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫—Ä—ã—Ç–∞")